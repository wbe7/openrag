"use strict";(self.webpackChunkopenrag_docs=self.webpackChunkopenrag_docs||[]).push([[2272],{3656:(e,n,s)=>{s.d(n,{Ay:()=>p,RM:()=>c});var o=s(4848),r=s(8453),i=s(1610),l=s(1470),t=s(9365);function a(e){const n={a:"a",code:"code",li:"li",ol:"ol",p:"p",strong:"strong",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"Using Ollama for your OpenRAG language model provider offers greater flexibility and configuration, but can also be overwhelming to start.\nThese recommendations are a reasonable starting point for users with at least one GPU and experience running LLMs locally."}),"\n",(0,o.jsxs)(n.p,{children:["For best performance, OpenRAG recommends OpenAI's ",(0,o.jsx)(n.code,{children:"gpt-oss:20b"})," language model. However, this model uses 16GB of RAM, so consider using Ollama Cloud or running Ollama on a remote machine."]}),"\n",(0,o.jsxs)(n.p,{children:["For generating embeddings, OpenRAG recommends the ",(0,o.jsx)(n.a,{href:"https://ollama.com/library/nomic-embed-text",children:(0,o.jsx)(n.code,{children:"nomic-embed-text"})})," embedding model, which provides high-quality embeddings optimized for retrieval tasks."]}),"\n",(0,o.jsxs)(n.p,{children:["To run models in ",(0,o.jsx)(n.a,{href:"https://docs.ollama.com/cloud",children:(0,o.jsx)(n.strong,{children:"Ollama Cloud"})}),", follow these steps:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Sign in to Ollama Cloud.\nIn a terminal, enter ",(0,o.jsx)(n.code,{children:"ollama signin"})," to connect your local environment with Ollama Cloud."]}),"\n",(0,o.jsxs)(n.li,{children:["To run the model, in Ollama, select the ",(0,o.jsx)(n.code,{children:"gpt-oss:20b-cloud"})," model, or run ",(0,o.jsx)(n.code,{children:"ollama run gpt-oss:20b-cloud"})," in a terminal.\nOllama Cloud models are run at the same URL as your local Ollama server at ",(0,o.jsx)(n.code,{children:"http://localhost:11434"}),", and automatically offloaded to Ollama's cloud service."]}),"\n",(0,o.jsxs)(n.li,{children:["Connect OpenRAG to the same local Ollama server as you would for local models in onboarding, using the default address of ",(0,o.jsx)(n.code,{children:"http://localhost:11434"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["In the ",(0,o.jsx)(n.strong,{children:"Language model"})," field, select the ",(0,o.jsx)(n.code,{children:"gpt-oss:20b-cloud"})," model."]}),"\n"]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsxs)(n.p,{children:["To run models on a ",(0,o.jsx)(n.strong,{children:"remote Ollama server"}),", follow these steps:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Ensure your remote Ollama server is accessible from your OpenRAG instance."}),"\n",(0,o.jsxs)(n.li,{children:["In the ",(0,o.jsx)(n.strong,{children:"Ollama Base URL"})," field, enter your remote Ollama server's base URL, such as ",(0,o.jsx)(n.code,{children:"http://your-remote-server:11434"}),".\nOpenRAG connects to the remote Ollama server and populates the lists with the server's available models."]}),"\n",(0,o.jsxs)(n.li,{children:["Select your ",(0,o.jsx)(n.strong,{children:"Embedding model"})," and ",(0,o.jsx)(n.strong,{children:"Language model"})," from the available options."]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(a,{...e})}):a(e)}const c=[{value:"Application onboarding",id:"application-onboarding",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",...(0,r.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"application-onboarding",children:"Application onboarding"}),"\n",(0,o.jsx)(n.p,{children:"The first time you start OpenRAG, regardless of how you installed it, you must complete application onboarding."}),"\n",(0,o.jsxs)(n.p,{children:["Some of these variables, such as the embedding models, can be changed seamlessly after onboarding.\nOthers are immutable and require you to destroy and recreate the OpenRAG containers.\nFor more information, see ",(0,o.jsx)(n.a,{href:"/reference/configuration",children:"Environment variables"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"You can use different providers for your language model and embedding model, such as Anthropic for the language model and OpenAI for the embeddings model.\nAdditionally, you can set multiple embedding models."}),"\n",(0,o.jsx)(n.p,{children:"You only need to complete onboarding for your preferred providers."}),"\n",(0,o.jsxs)(l.A,{groupId:"Provider",children:[(0,o.jsxs)(t.A,{value:"Anthropic",label:"Anthropic",default:!0,children:[(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsx)(n.p,{children:"Anthropic doesn't provide embedding models. If you select Anthropic for your language model, you must select a different provider for embeddings."})}),(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Enable ",(0,o.jsx)(n.strong,{children:"Use environment Anthropic API key"})," to automatically use your key from the ",(0,o.jsx)(n.code,{children:".env"})," file.\nAlternatively, paste an Anthropic API key into the field."]}),"\n",(0,o.jsxs)(n.li,{children:["Under ",(0,o.jsx)(n.strong,{children:"Advanced settings"}),", select your ",(0,o.jsx)(n.strong,{children:"Language Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Click ",(0,o.jsx)(n.strong,{children:"Complete"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["In the second onboarding panel, select a provider for embeddings and select your ",(0,o.jsx)(n.strong,{children:"Embedding Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["To complete the onboarding tasks, click ",(0,o.jsx)(n.strong,{children:"What is OpenRAG"}),", and then click ",(0,o.jsx)(n.strong,{children:"Add a Document"}),".\nAlternatively, click ",(0,o.jsx)(i.A,{name:"ArrowRight","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Skip overview"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Continue with the ",(0,o.jsx)(n.a,{href:"/quickstart",children:"Quickstart"}),"."]}),"\n"]})]}),(0,o.jsx)(t.A,{value:"OpenAI",label:"OpenAI",children:(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Enable ",(0,o.jsx)(n.strong,{children:"Get API key from environment variable"})," to automatically enter your key from the TUI-generated ",(0,o.jsx)(n.code,{children:".env"})," file.\nAlternatively, paste an OpenAI API key into the field."]}),"\n",(0,o.jsxs)(n.li,{children:["Under ",(0,o.jsx)(n.strong,{children:"Advanced settings"}),", select your ",(0,o.jsx)(n.strong,{children:"Language Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Click ",(0,o.jsx)(n.strong,{children:"Complete"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["In the second onboarding panel, select a provider for embeddings and select your ",(0,o.jsx)(n.strong,{children:"Embedding Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["To complete the onboarding tasks, click ",(0,o.jsx)(n.strong,{children:"What is OpenRAG"}),", and then click ",(0,o.jsx)(n.strong,{children:"Add a Document"}),".\nAlternatively, click ",(0,o.jsx)(i.A,{name:"ArrowRight","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Skip overview"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Continue with the ",(0,o.jsx)(n.a,{href:"/quickstart",children:"Quickstart"}),"."]}),"\n"]})}),(0,o.jsx)(t.A,{value:"IBM watsonx.ai",label:"IBM watsonx.ai",children:(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Complete the fields for ",(0,o.jsx)(n.strong,{children:"watsonx.ai API Endpoint"}),", ",(0,o.jsx)(n.strong,{children:"IBM Project ID"}),", and ",(0,o.jsx)(n.strong,{children:"IBM API key"}),".\nThese values are found in your IBM watsonx deployment."]}),"\n",(0,o.jsxs)(n.li,{children:["Under ",(0,o.jsx)(n.strong,{children:"Advanced settings"}),", select your ",(0,o.jsx)(n.strong,{children:"Language Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Click ",(0,o.jsx)(n.strong,{children:"Complete"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["In the second onboarding panel, select a provider for embeddings and select your ",(0,o.jsx)(n.strong,{children:"Embedding Model"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["To complete the onboarding tasks, click ",(0,o.jsx)(n.strong,{children:"What is OpenRAG"}),", and then click ",(0,o.jsx)(n.strong,{children:"Add a Document"}),".\nAlternatively, click ",(0,o.jsx)(i.A,{name:"ArrowRight","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Skip overview"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Continue with the ",(0,o.jsx)(n.a,{href:"/quickstart",children:"Quickstart"}),"."]}),"\n"]})}),(0,o.jsxs)(t.A,{value:"Ollama",label:"Ollama",children:[(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["Ollama isn't installed with OpenRAG. To install Ollama, see the ",(0,o.jsx)(n.a,{href:"https://docs.ollama.com/",children:"Ollama documentation"}),"."]})}),(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["To connect to an Ollama server running on your local machine, enter your Ollama server's base URL address.\nThe default Ollama server address is ",(0,o.jsx)(n.code,{children:"http://localhost:11434"}),".\nOpenRAG connects to the Ollama server and populates the model lists with the server's available models."]}),"\n",(0,o.jsxs)(n.li,{children:["Select the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," and ",(0,o.jsx)(n.strong,{children:"Language Model"})," your Ollama server is running.","\n",(0,o.jsxs)(s,{closed:!0,children:[(0,o.jsx)("summary",{children:"Ollama model selection and external server configuration"}),(0,o.jsx)(d,{})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Click ",(0,o.jsx)(n.strong,{children:"Complete"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["To complete the onboarding tasks, click ",(0,o.jsx)(n.strong,{children:"What is OpenRAG"}),", and then click ",(0,o.jsx)(n.strong,{children:"Add a Document"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Continue with the ",(0,o.jsx)(n.a,{href:"/quickstart",children:"Quickstart"}),"."]}),"\n"]})]})]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},3862:(e,n,s)=>{s.d(n,{Ay:()=>t,RM:()=>i});var o=s(4848),r=s(8453);const i=[];function l(e){const n={a:"a",admonition:"admonition",code:"code",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/install",children:"Install WSL"})," with the Ubuntu distribution using WSL 2:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-powershell",children:"wsl --install -d Ubuntu\n"})}),"\n",(0,o.jsxs)(n.p,{children:["For new installations, the ",(0,o.jsx)(n.code,{children:"wsl --install"})," command uses WSL 2 and Ubuntu by default."]}),"\n",(0,o.jsxs)(n.p,{children:["For existing WSL installations, you can ",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/install#change-the-default-linux-distribution-installed",children:"change the distribution"})," and ",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/install#upgrade-version-from-wsl-1-to-wsl-2",children:"check the WSL version"}),"."]}),"\n",(0,o.jsx)(n.admonition,{title:"Known limitation",type:"warning",children:(0,o.jsx)(n.p,{children:"OpenRAG isn't compatible with nested virtualization, which can cause networking issues.\nDon't install OpenRAG on a WSL distribution that is installed inside a Windows VM.\nInstead, install OpenRAG on your base OS or a non-nested Linux VM."})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/install#ways-to-run-multiple-linux-distributions-with-wsl",children:"Start your WSL Ubuntu distribution"})," if it doesn't start automatically."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/setup/environment#set-up-your-linux-username-and-password",children:"Set up a username and password for your WSL distribution"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers",children:"Install Docker Desktop for Windows with WSL 2"}),". When you reach the Docker Desktop ",(0,o.jsx)(n.strong,{children:"WSL integration"})," settings, make sure your Ubuntu distribution is enabled, and then click ",(0,o.jsx)(n.strong,{children:"Apply & Restart"})," to enable Docker support in WSL."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Install and run OpenRAG from within your WSL Ubuntu distribution."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsxs)(n.p,{children:["If you encounter issues with port forwarding or the Windows Firewall, you might need to adjust the ",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/hyper-v-firewall",children:"Hyper-V firewall settings"})," to allow communication between your WSL distribution and the Windows host. For more troubleshooting advice for networking issues, see ",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/windows/wsl/troubleshooting#common-issues",children:"Troubleshooting WSL common issues"}),"."]})]})}function t(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},5788:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>p,contentTitle:()=>h,default:()=>x,frontMatter:()=>c,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"get-started/docker","title":"Install OpenRAG containers","description":"OpenRAG has two Docker Compose files. Both files deploy the same applications and containers locally, but they are for different environments:","source":"@site/docs/get-started/docker.mdx","sourceDirName":"get-started","slug":"/docker","permalink":"/docker","draft":false,"unlisted":false,"editUrl":"https://github.com/openrag/openrag/tree/main/docs/docs/get-started/docker.mdx","tags":[],"version":"current","frontMatter":{"title":"Install OpenRAG containers","slug":"/docker"},"sidebar":"tutorialSidebar","previous":{"title":"Install OpenRAG with TUI","permalink":"/install"},"next":{"title":"Flows","permalink":"/agents"}}');var r=s(4848),i=s(8453),l=s(1470),t=s(9365),a=s(3656),d=s(3862);const c={title:"Install OpenRAG containers",slug:"/docker"},h=void 0,p={},u=[{value:"Prerequisites",id:"prerequisites",level:2},...d.RM,{value:"Install OpenRAG with Docker Compose",id:"install-openrag-with-docker-compose",level:2},...a.RM,{value:"Container management commands",id:"container-management-commands",level:2},{value:"Upgrade containers",id:"upgrade-containers",level:3},{value:"Rebuild containers (destructive)",id:"rebuild-containers-destructive",level:3},{value:"Remove all containers and data (destructive)",id:"remove-all-containers-and-data-destructive",level:3}];function m(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"OpenRAG has two Docker Compose files. Both files deploy the same applications and containers locally, but they are for different environments:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/langflow-ai/openrag/blob/main/docker-compose.yml",children:(0,r.jsx)(n.code,{children:"docker-compose.yml"})})," is an OpenRAG deployment with GPU support for accelerated AI processing. This Docker Compose file requires an NVIDIA GPU with ",(0,r.jsx)(n.a,{href:"https://docs.nvidia.com/cuda/",children:"CUDA"})," support."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/langflow-ai/openrag/blob/main/docker-compose-cpu.yml",children:(0,r.jsx)(n.code,{children:"docker-compose-cpu.yml"})})," is a CPU-only version of OpenRAG for systems without NVIDIA GPU support. Use this Docker Compose file for environments where GPU drivers aren't available."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install the following:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://www.python.org/downloads/release/python-3100/",children:"Python"})," version 3.13 or later."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.astral.sh/uv/getting-started/installation/",children:"uv"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://podman.io/docs/installation",children:"Podman"})," (recommended) or ",(0,r.jsx)(n.a,{href:"https://docs.docker.com/get-docker/",children:"Docker"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://docs.podman.io/en/latest/markdown/podman-compose.1.html",children:(0,r.jsx)(n.code,{children:"podman-compose"})})," or ",(0,r.jsx)(n.a,{href:"https://docs.docker.com/compose/install/",children:"Docker Compose"}),". To use Docker Compose with Podman, you must alias Docker Compose commands to Podman commands."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Microsoft Windows only: To run OpenRAG on Windows, you must use the Windows Subsystem for Linux (WSL)."}),"\n",(0,r.jsxs)(s,{children:[(0,r.jsx)("summary",{children:"Install WSL for OpenRAG"}),(0,r.jsx)(d.Ay,{})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Prepare model providers and credentials."}),"\n",(0,r.jsxs)(n.p,{children:["During ",(0,r.jsx)(n.a,{href:"#application-onboarding",children:"application onboarding"}),", you must select language model and embedding model providers.\nIf your chosen provider offers both types, you can use the same provider for both selections.\nIf your provider offers only one type, such as Anthropic, you must select two providers."]}),"\n",(0,r.jsx)(n.p,{children:"Gather the credentials and connection details for your chosen model providers before starting onboarding:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["OpenAI: Create an ",(0,r.jsx)(n.a,{href:"https://platform.openai.com/api-keys",children:"OpenAI API key"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Anthropic language models: Create an ",(0,r.jsx)(n.a,{href:"https://www.anthropic.com/docs/api/reference",children:"Anthropic API key"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"IBM watsonx.ai: Get your watsonx.ai API endpoint, IBM project ID, and IBM API key from your watsonx deployment."}),"\n",(0,r.jsxs)(n.li,{children:["Ollama: Use the ",(0,r.jsx)(n.a,{href:"https://docs.ollama.com/",children:"Ollama documentation"})," to set up your Ollama instance locally, in the cloud, or on a remote server, and then get your Ollama server's base URL."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Optional: Install GPU support with an NVIDIA GPU, ",(0,r.jsx)(n.a,{href:"https://docs.nvidia.com/cuda/",children:"CUDA"})," support, and compatible NVIDIA drivers on the OpenRAG host machine. This is required to use the GPU-accelerated Docker Compose file. If you choose not to use GPU support, you must use the CPU-only Docker Compose file instead."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"install-openrag-with-docker-compose",children:"Install OpenRAG with Docker Compose"}),"\n",(0,r.jsx)(n.p,{children:"To install OpenRAG with Docker Compose, do the following:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Clone the OpenRAG repository."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/langflow-ai/openrag.git\ncd openrag\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install dependencies."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uv sync\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Copy the example ",(0,r.jsx)(n.code,{children:".env"})," file included in the repository root.\nThe example file includes all environment variables with comments to guide you in finding and setting their values."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cp .env.example .env\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Alternatively, create a new ",(0,r.jsx)(n.code,{children:".env"})," file in the repository root."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"touch .env\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["The Docker Compose files are populated with the values from your ",(0,r.jsx)(n.code,{children:".env"})," file.\nThe ",(0,r.jsx)(n.code,{children:"OPENSEARCH_PASSWORD"})," value must be set.\n",(0,r.jsx)(n.code,{children:"OPENSEARCH_PASSWORD"})," can be automatically generated when using the TUI, but for a Docker Compose installation, you can set it manually instead. To generate an OpenSearch admin password, see the ",(0,r.jsx)(n.a,{href:"https://docs.opensearch.org/latest/security/configuration/demo-configuration/#setting-up-a-custom-admin-password",children:"OpenSearch documentation"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"The following values are optional:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"OPENAI_API_KEY=your_openai_api_key\nLANGFLOW_SECRET_KEY=your_secret_key\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"OPENAI_API_KEY"})," is optional. You can provide it during ",(0,r.jsx)(n.a,{href:"#application-onboarding",children:"application onboarding"})," or choose a different model provider. If you want to set it in your ",(0,r.jsx)(n.code,{children:".env"})," file, you can find your OpenAI API key in your ",(0,r.jsx)(n.a,{href:"https://platform.openai.com/api-keys",children:"OpenAI account"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"LANGFLOW_SECRET_KEY"})," is optional. Langflow will auto-generate it if not set. For more information, see the ",(0,r.jsx)(n.a,{href:"https://docs.langflow.org/api-keys-and-authentication#langflow-secret-key",children:"Langflow documentation"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"The following Langflow configuration values are optional but important to consider:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"LANGFLOW_SUPERUSER=admin\nLANGFLOW_SUPERUSER_PASSWORD=your_langflow_password\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"LANGFLOW_SUPERUSER"})," defaults to ",(0,r.jsx)(n.code,{children:"admin"}),". You can omit it or set it to a different username. ",(0,r.jsx)(n.code,{children:"LANGFLOW_SUPERUSER_PASSWORD"})," is optional. If omitted, Langflow runs in ",(0,r.jsx)(n.a,{href:"https://docs.langflow.org/api-keys-and-authentication#langflow-auto-login",children:"autologin mode"})," with no password required. If set, Langflow requires password authentication."]}),"\n",(0,r.jsxs)(n.p,{children:["For more information on configuring OpenRAG with environment variables, see ",(0,r.jsx)(n.a,{href:"/reference/configuration",children:"Environment variables"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Start ",(0,r.jsx)(n.code,{children:"docling serve"})," on the host machine.\nOpenRAG Docker installations require that ",(0,r.jsx)(n.code,{children:"docling serve"})," is running on port 5001 on the host machine.\nThis enables ",(0,r.jsx)(n.a,{href:"https://opensource.apple.com/projects/mlx/",children:"Mac MLX"})," support for document processing."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uv run python scripts/docling_ctl.py start --port 5001\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Confirm ",(0,r.jsx)(n.code,{children:"docling serve"})," is running."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"uv run python scripts/docling_ctl.py status\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Make sure the response shows that ",(0,r.jsx)(n.code,{children:"docling serve"})," is running, for example:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Status: running\nEndpoint: http://127.0.0.1:5001\nDocs: http://127.0.0.1:5001/docs\nPID: 27746\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Deploy OpenRAG locally with Docker Compose based on your deployment type."}),"\n",(0,r.jsxs)(l.A,{groupId:"Compose file",children:[(0,r.jsx)(t.A,{value:"docker-compose.yml",label:"docker-compose.yml",default:!0,children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose build\ndocker compose up -d\n"})})}),(0,r.jsx)(t.A,{value:"docker-compose-cpu.yml",label:"docker-compose-cpu.yml",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose -f docker-compose-cpu.yml up -d\n"})})})]}),"\n",(0,r.jsx)(n.p,{children:"The OpenRAG Docker Compose file starts five containers:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Container Name"}),(0,r.jsx)(n.th,{children:"Default Address"}),(0,r.jsx)(n.th,{children:"Purpose"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"OpenRAG Backend"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"http://localhost:8000",children:"http://localhost:8000"})}),(0,r.jsx)(n.td,{children:"FastAPI server and core functionality."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"OpenRAG Frontend"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"http://localhost:3000",children:"http://localhost:3000"})}),(0,r.jsx)(n.td,{children:"React web interface for users."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Langflow"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"http://localhost:7860",children:"http://localhost:7860"})}),(0,r.jsx)(n.td,{children:"AI workflow engine and flow management."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"OpenSearch"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"http://localhost:9200",children:"http://localhost:9200"})}),(0,r.jsx)(n.td,{children:"Vector database for document storage."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"OpenSearch Dashboards"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"http://localhost:5601",children:"http://localhost:5601"})}),(0,r.jsx)(n.td,{children:"Database administration interface."})]})]})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Verify installation by confirming all services are running."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose ps\n"})}),"\n",(0,r.jsx)(n.p,{children:"You can now access OpenRAG at the following endpoints:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Frontend"}),": ",(0,r.jsx)(n.a,{href:"http://localhost:3000",children:"http://localhost:3000"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Backend API"}),": ",(0,r.jsx)(n.a,{href:"http://localhost:8000",children:"http://localhost:8000"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Langflow"}),": ",(0,r.jsx)(n.a,{href:"http://localhost:7860",children:"http://localhost:7860"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Continue with ",(0,r.jsx)(n.a,{href:"#application-onboarding",children:"application onboarding"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To stop ",(0,r.jsx)(n.code,{children:"docling serve"})," when you're done with your OpenRAG deployment, run:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"uv run python scripts/docling_ctl.py stop\n"})}),"\n",(0,r.jsx)(a.Ay,{}),"\n",(0,r.jsx)(n.h2,{id:"container-management-commands",children:"Container management commands"}),"\n",(0,r.jsxs)(n.p,{children:["Manage your OpenRAG containers with the following commands.\nThese commands are also available in the TUI's ",(0,r.jsx)(n.a,{href:"/install#status",children:"Status menu"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"upgrade-containers",children:"Upgrade containers"}),"\n",(0,r.jsx)(n.p,{children:"Upgrade your containers to the latest version while preserving your data."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose pull\ndocker compose up -d --force-recreate\n"})}),"\n",(0,r.jsx)(n.h3,{id:"rebuild-containers-destructive",children:"Rebuild containers (destructive)"}),"\n",(0,r.jsxs)(n.p,{children:["Reset state by rebuilding all of your containers.\nYour OpenSearch and Langflow databases will be lost.\nDocuments stored in the ",(0,r.jsx)(n.code,{children:"./openrag-documents"})," directory will persist, since the directory is mounted as a volume in the OpenRAG backend container."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose up --build --force-recreate --remove-orphans\n"})}),"\n",(0,r.jsx)(n.h3,{id:"remove-all-containers-and-data-destructive",children:"Remove all containers and data (destructive)"}),"\n",(0,r.jsx)(n.p,{children:"Completely remove your OpenRAG installation and delete all data.\nThis deletes all of your data, including OpenSearch data, uploaded documents, and authentication."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"docker compose down --volumes --remove-orphans --rmi local\ndocker system prune -f\n"})})]})}function x(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}}}]);