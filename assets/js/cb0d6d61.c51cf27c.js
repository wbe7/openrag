"use strict";(globalThis.webpackChunkopenrag_docs=globalThis.webpackChunkopenrag_docs||[]).push([[8897],{2169:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>g,frontMatter:()=>c,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"core-components/ingestion-configure","title":"Configure ingestion","description":"The knowledge ingestion settings determine how documents are processed when you upload documents into your knowledge base.","source":"@site/docs/core-components/ingestion-configure.mdx","sourceDirName":"core-components","slug":"/ingestion-configure","permalink":"/ingestion-configure","draft":false,"unlisted":false,"editUrl":"https://github.com/openrag/openrag/tree/main/docs/docs/core-components/ingestion-configure.mdx","tags":[],"version":"current","frontMatter":{"title":"Configure ingestion","slug":"/ingestion-configure"},"sidebar":"tutorialSidebar","previous":{"title":"Ingest knowledge","permalink":"/ingestion"},"next":{"title":"Browse and manage knowledge","permalink":"/knowledge-browse"}}');var t=s(4848),o=s(8453),r=s(9179);const c={title:"Configure ingestion",slug:"/ingestion-configure"},a=void 0,l={},d=[{value:"Existing documents aren&#39;t reprocessed after changing ingestion settings",id:"existing-documents-arent-reprocessed-after-changing-ingestion-settings",level:2},{value:"Select a Docling implementation",id:"select-a-docling-implementation",level:2},{value:"Set the embedding model and dimensions",id:"set-the-embedding-model-and-dimensions",level:2},{value:"Best practices for multiple embedding models",id:"best-practices-for-multiple-embedding-models",level:3},{value:"Set the chunking strategy",id:"set-the-chunking-strategy",level:2},{value:"Configure table parsing",id:"configure-table-parsing",level:2},{value:"Configure OCR and image processing",id:"configure-ocr-and-image-processing",level:2},{value:"Set the local documents path",id:"set-the-local-documents-path",level:2},{value:"See also",id:"see-also",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["The knowledge ingestion settings determine how documents are processed when you ",(0,t.jsx)(n.a,{href:"/ingestion",children:"upload documents"})," into your ",(0,t.jsx)(n.a,{href:"/knowledge",children:"knowledge base"}),".\nThis includes chunking strategies, embedding models, and image handling settings."]}),"\n",(0,t.jsx)(n.h2,{id:"existing-documents-arent-reprocessed-after-changing-ingestion-settings",children:"Existing documents aren't reprocessed after changing ingestion settings"}),"\n",(0,t.jsx)(n.admonition,{type:"warning",children:(0,t.jsx)(n.p,{children:"Changes to knowledge ingestion settings only apply to documents that you upload after making changes.\nDocuments uploaded before changing these settings aren't reprocessed."})}),"\n",(0,t.jsx)(n.p,{children:"After changing knowledge ingestion settings, you must determine if you need to reupload any documents to be consistent with the new settings."}),"\n",(0,t.jsx)(n.p,{children:"It isn't always necessary to reupload documents after changing knowledge ingestion settings.\nFor example, it is typical to upload some documents with OCR enabled and others without OCR enabled."}),"\n",(0,t.jsxs)(n.p,{children:["If needed, you can use ",(0,t.jsx)(n.a,{href:"/knowledge-filters",children:"filters"})," to separate documents that you uploaded with different settings, such as different embedding models."]}),"\n",(0,t.jsx)(n.h2,{id:"select-a-docling-implementation",children:"Select a Docling implementation"}),"\n",(0,t.jsxs)(n.p,{children:["OpenRAG uses ",(0,t.jsx)(n.a,{href:"https://docling-project.github.io/docling/",children:"Docling"})," for document ingestion.\nDocling processes files, splits them into chunks, and stores them as separate, structured documents in your OpenSearch knowledge base."]}),"\n",(0,t.jsx)(n.p,{children:"You can configure OpenRAG to use either a Docling Serve service or a Docling processor pipeline for document processing:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Docling Serve ingestion"}),": By default, OpenRAG uses ",(0,t.jsx)(n.a,{href:"https://github.com/docling-project/docling-serve",children:"Docling Serve"}),".\nWhen you start OpenRAG, a local ",(0,t.jsx)(n.code,{children:"docling serve"})," process starts, and then OpenRAG runs Docling ingestion through the Docling Serve API."]}),"\n",(0,t.jsxs)(n.p,{children:["To use a remote ",(0,t.jsx)(n.code,{children:"docling serve"})," instance or your own local instance, set ",(0,t.jsx)(n.code,{children:"DOCLING_SERVE_URL=http://HOST_IP:5001"})," in your ",(0,t.jsxs)(n.a,{href:"/reference/configuration#document-processing-settings",children:["OpenRAG ",(0,t.jsx)(n.code,{children:".env"})," file"]}),".\nThe service must run on port 5001."]}),"\n",(0,t.jsxs)(n.p,{children:["For TUI-managed deployments, The TUI warns you if ",(0,t.jsx)(n.code,{children:"docling serve"})," isn't running or isn't detected by OpenRAG.\nFor information about starting and stopping OpenRAG services, see ",(0,t.jsx)(n.a,{href:"/manage-services",children:"Manage OpenRAG services"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Docling processor ingestion"}),": Instead of using a separate Docling Serve service and the Docling Serve API, you can use the Docling processor directly.\nTo do this, set ",(0,t.jsx)(n.code,{children:"DISABLE_INGEST_WITH_LANGFLOW=true"})," in your ",(0,t.jsxs)(n.a,{href:"/reference/configuration#document-processing-settings",children:["OpenRAG ",(0,t.jsx)(n.code,{children:".env"})," file"]}),", and then ",(0,t.jsx)(n.a,{href:"/manage-services",children:"restart the OpenRAG services"}),".\nFor the underlying functionality for this option, see ",(0,t.jsx)(n.a,{href:"https://github.com/langflow-ai/openrag/blob/main/src/models/processors.py#L58",children:(0,t.jsx)(n.code,{children:"processors.py"})})," in the OpenRAG repository."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"set-the-embedding-model-and-dimensions",children:"Set the embedding model and dimensions"}),"\n",(0,t.jsxs)(n.p,{children:["When you install OpenRAG, you select at least one embedding model during the ",(0,t.jsx)(n.a,{href:"/install-uvx#application-onboarding",children:"application onboarding process"}),".\nOpenRAG automatically detects and configures the appropriate vector dimensions for your selected embedding model, ensuring optimal search performance and compatibility."]}),"\n",(0,t.jsxs)(n.p,{children:["After onboarding, you can change the embedding model on the OpenRAG ",(0,t.jsx)(r.A,{name:"Settings2","aria-hidden":"true"})," ",(0,t.jsx)(n.strong,{children:"Settings"})," page.\nOpenRAG automatically updates all relevant ",(0,t.jsx)(n.a,{href:"/agents",children:"OpenRAG flows"})," to use the new embedding model and dimensions."]}),"\n",(0,t.jsxs)(n.p,{children:["You can only select models that are available from your configured model providers, such as an Ollama instance or an OpenAI account.\nFor more information, see ",(0,t.jsx)(n.a,{href:"/support/troubleshoot#model-availability-and-performance-issues",children:"Troubleshoot model availability and performance issues"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Because the OpenRAG UI validates model availability and compatibility, setting models directly in the ",(0,t.jsxs)(n.a,{href:"/reference/configuration",children:["OpenRAG ",(0,t.jsx)(n.code,{children:".env"})," file"]})," isn't recommended."]}),"\n",(0,t.jsx)(n.h3,{id:"best-practices-for-multiple-embedding-models",children:"Best practices for multiple embedding models"}),"\n",(0,t.jsx)(n.p,{children:"For ingestion, OpenRAG allows only one active embedding model at a time."}),"\n",(0,t.jsxs)(n.p,{children:["OpenRAG ",(0,t.jsx)(n.em,{children:"doesn't"})," reprocess existing documents when you change the embedding model.\nIf you want to generate new embeddings for existing documents, you must reupload the documents after enabling the new embedding model.\nTo remove previously generated embeddings, you must delete the existing document from the knowledge base."]}),"\n",(0,t.jsxs)(n.p,{children:["If you use different embedding models for different documents, you can create ",(0,t.jsx)(n.a,{href:"/knowledge-filters",children:"filters"})," to separate documents that were embedded with different models."]}),"\n",(0,t.jsxs)(n.p,{children:["If you use multiple embeddings models, be aware that similarity search (in ",(0,t.jsx)(n.strong,{children:"Chat"}),") can take longer as the agent searches each model's embeddings separately."]}),"\n",(0,t.jsx)(n.h2,{id:"set-the-chunking-strategy",children:"Set the chunking strategy"}),"\n",(0,t.jsxs)(n.p,{children:["You can edit the following settings on the OpenRAG ",(0,t.jsx)(r.A,{name:"Settings2","aria-hidden":"true"})," ",(0,t.jsx)(n.strong,{children:"Settings"})," page in the ",(0,t.jsx)(n.strong,{children:"Knowledge Ingest"})," section:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Chunk size"}),": Set the number of characters for each text chunk when breaking down a file.\nLarger chunks yield more context per chunk, but can include irrelevant information. Smaller chunks yield more precise semantic search, but can lack context.\nThe default value is 1000 characters, which is usually a good balance between context and precision."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Chunk overlap"}),": Set the number of characters to overlap over chunk boundaries.\nUse larger overlap values for documents where context is most important. Use smaller overlap values for simpler documents or when optimization is most important.\nThe default value is 200 characters, which represents an overlap of 20 percent with the default ",(0,t.jsx)(n.strong,{children:"Chunk size"})," of 1000. This is suitable for general use. For faster processing, decrease the overlap to approximately 10 percent. For more complex documents where you need to preserve context across chunks, increase it to approximately 40 percent."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"configure-table-parsing",children:"Configure table parsing"}),"\n",(0,t.jsxs)(n.p,{children:["You can edit the following setting on the OpenRAG ",(0,t.jsx)(r.A,{name:"Settings2","aria-hidden":"true"})," ",(0,t.jsx)(n.strong,{children:"Settings"})," page in the ",(0,t.jsx)(n.strong,{children:"Knowledge Ingest"})," section:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Table structure"}),": Enables Docling's ",(0,t.jsx)(n.a,{href:"https://docling-project.github.io/docling/reference/document_converter/",children:(0,t.jsx)(n.code,{children:"DocumentConverter"})})," tool for parsing tables. Instead of treating tables as plain text, tables are output as structured table data with preserved relationships and metadata. This option is enabled by default."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"configure-ocr-and-image-processing",children:"Configure OCR and image processing"}),"\n",(0,t.jsxs)(n.p,{children:["You can edit the following settings on the OpenRAG ",(0,t.jsx)(r.A,{name:"Settings2","aria-hidden":"true"})," ",(0,t.jsx)(n.strong,{children:"Settings"})," page in the ",(0,t.jsx)(n.strong,{children:"Knowledge Ingest"})," section:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"OCR"}),": Enables Optical Character Recognition (OCR) processing when extracting text from images and ingesting scanned documents. This setting is best suited for processing text-based documents faster with Docling's ",(0,t.jsx)(n.a,{href:"https://docling-project.github.io/docling/reference/document_converter/",children:(0,t.jsx)(n.code,{children:"DocumentConverter"})}),". Images are ignored and not processed."]}),"\n",(0,t.jsx)(n.p,{children:"This option is disabled by default. Enabling OCR can slow ingestion performance."}),"\n",(0,t.jsxs)(n.p,{children:["If OpenRAG detects that the local machine is running on macOS, OpenRAG uses the ",(0,t.jsx)(n.a,{href:"https://www.piwheels.org/project/ocrmac/",children:"ocrmac"})," OCR engine. Other platforms use ",(0,t.jsx)(n.a,{href:"https://www.jaided.ai/easyocr/",children:"easyocr"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Picture descriptions"}),": Only applicable if ",(0,t.jsx)(n.strong,{children:"OCR"})," is enabled. Adds image descriptions generated by the ",(0,t.jsx)(n.a,{href:"https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct",children:(0,t.jsx)(n.code,{children:"SmolVLM-256M-Instruct"})})," model. Enabling picture descriptions can slow ingestion performance."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"set-the-local-documents-path",children:"Set the local documents path"}),"\n",(0,t.jsx)(n.p,{children:"The local documents paths is set when you install OpenRAG and start the OpenRAG services."}),"\n",(0,t.jsxs)(n.p,{children:["The default path for local uploads is ",(0,t.jsx)(n.code,{children:"~/.openrag/documents"}),".\nThis is mounted to the ",(0,t.jsx)(n.code,{children:"/app/openrag-documents/"})," directory inside the OpenRAG container.\nFiles added to the host or container directory are visible in both locations."]}),"\n",(0,t.jsxs)(n.p,{children:["To change this location, modify either of the following, and then ",(0,t.jsx)(n.a,{href:"/manage-services",children:"restart the OpenRAG services"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.strong,{children:"Documents Paths"})," setting in the ",(0,t.jsxs)(n.a,{href:"/install-uvx#setup",children:[(0,t.jsx)(n.strong,{children:"Basic/Advanced Setup"})," menu"]})]}),"\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.code,{children:"OPENRAG_DOCUMENTS_PATH"})," variable in the ",(0,t.jsxs)(n.a,{href:"/reference/configuration",children:["OpenRAG ",(0,t.jsx)(n.code,{children:".env"})," file"]}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"see-also",children:"See also"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/knowledge",children:"About knowledge"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/ingestion",children:"Ingest knowledge"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/knowledge-browse",children:"Browse and manage knowledge"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/knowledge-connectors",children:"Configure connectors"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/agents#inspect-and-modify-flows",children:"Inspect and modify flows"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/support/troubleshoot#document-ingestion-or-similarity-search-issues",children:"Troubleshoot document ingestion or similarity search issues"})}),"\n"]})]})}function g(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},9179:(e,n,s)=>{s.d(n,{A:()=>o});s(6540);var i=s(7856),t=s(4848);function o({name:e,...n}){const s=i[e];return s?(0,t.jsx)(s,{...n}):null}}}]);