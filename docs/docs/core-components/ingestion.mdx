---
title: Ingest knowledge
slug: /ingestion
---

import Icon from "@site/src/components/icon/icon";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import PartialTempKnowledge from '@site/docs/_partial-temp-knowledge.mdx';
import PartialIngestionFlow from '@site/docs/_partial-ingestion-flow.mdx';
import PartialDockerComposeUp from '@site/docs/_partial-docker-compose-up.mdx';
import PartialDockerStopAll from '@site/docs/_partial-docker-stop-all.mdx';
import PartialOAuthCredentials from '@site/docs/_partial-oauth-credentials.mdx';

Upload documents to your [OpenRAG OpenSearch instance](/knowledge) to populate your knowledge base with unique content, such as your own company documents, research papers, or websites.
Documents are processed through OpenRAG's knowledge ingestion flows with Docling.

OpenRAG can ingest knowledge from direct file uploads, URLs, and cloud storage connectors.

Knowledge ingestion is powered by OpenRAG's built-in knowledge ingestion flows that use Docling to process documents before storing the documents in your OpenSearch database.
During ingestion, documents are broken into smaller chunks of content that are then embedded using your selected [embedding model](/knowledge#set-the-embedding-model-and-dimensions).
Then, the chunks, embeddings, and associated metadata (which connects chunks of the same document) are stored in your OpenSearch database.

To modify chunking behavior and other ingestion settings, see [Knowledge ingestion settings](/knowledge#knowledge-ingestion-settings) and [Inspect and modify flows](/agents#inspect-and-modify-flows).

## Ingest local files and folders

You can upload files and folders from your local machine to your knowledge base:

1. Click <Icon name="Library" aria-hidden="true"/> **Knowledge** to view your OpenSearch knowledge base.

2. Click **Add Knowledge** to add your own documents to your OpenRAG knowledge base.

3. To upload one file, click <Icon name="File" aria-hidden="true"/> **File**. To upload all documents in a folder, click <Icon name="Folder" aria-hidden="true"/> **Folder**.

   The default path is `~/.openrag/documents`.
   To change this path, see [Set the local documents path](/knowledge#set-the-local-documents-path).

The selected files are processed in the background through the **OpenSearch Ingestion** flow.

<PartialIngestionFlow />

You can [monitor ingestion](#monitor-ingestion) to see the progress of the uploads and check for failed uploads.

## Ingest local files temporarily

<PartialTempKnowledge />

## Ingest files with cloud storage connectors {#oauth-ingestion}

OpenRAG can use cloud storage connectors to ingest documents from the following external services:

* AWS S3
* Google Drive
* Microsoft OneDrive
* Microsoft Sharepoint

These connectors enable seamless ingestion of files from cloud storage to your OpenRAG knowledge base.

OAuth credentials are used to authorize access to cloud storage services.

### Configure cloud storage connectors

Before you can ingest documents from cloud storage, you must authorize OpenRAG's access to your cloud storage services.

Typically, this requires that you register OpenRAG as an OAuth application in your cloud provider, and then obtain the app's OAuth credentials, such as a client ID and secret key.
To enable multiple connectors, you must register an app and generate credentials for each provider.

Then, add the OAuth credentials to your OpenRAG configuration:

<Tabs>
<TabItem value="TUI" label="TUI-managed services" default>

If you use the [Terminal User Interface (TUI)](/tui) to manage your OpenRAG services, enter OAuth credentials on the **Advanced Setup** page.
You can do this during [installation](/install#setup), or you can add the credentials afterwards:

1. If OpenRAG is running, click **Stop All Services** in the TUI.

2. Open the **Advanced Setup** page, and then add the OAuth credentials for the cloud storage providers that you want to use under **API Keys**:

   <PartialOAuthCredentials />

3. For each connector you configured, register the redirect URIs shown in the TUI in your OAuth apps.

   The redirect URIs are used for the cloud storage connector webhooks. For Google, the redirect URIs are also used to redirect users back to OpenRAG after they sign in.

4. Optional: Under **Others**, set the **Webhook Base URL** to the base address for your OAuth connector endpoints. If set, the OAuth connector webhook URLs are constructed as `WEBHOOK_BASE_URL/connectors/${provider}/webhook`. This option is required to enable automatic ingestion from cloud storage.

5. Click **Save Configuration** to add the OAuth credentials to your [OpenRAG `.env` file](/reference/configuration).

6. Click **Start Services** to restart the OpenRAG containers with the new configuration.

7. Launch the OpenRAG app.

   If you provided Google OAuth credentials, you must sign in with Google before you are redirected to your OpenRAG instance.

</TabItem>
<TabItem value="env" label="Self-managed services">

If you [installed OpenRAG with self-managed services](/docker), set OAuth credentials in your [OpenRAG `.env` file](/reference/configuration).

You can do this during [initial set up](/docker#setup), or you can add the credentials afterwards:

1. Stop all OpenRAG containers:

   <PartialDockerStopAll />

2. Edit your OpenRAG `.env` file, and then add the [OAuth and cloud storage environment variables](/reference/configuration#oauth-and-cloud-storage-connector-settings) for the providers that you want to use:

   ```env
   GOOGLE_OAUTH_CLIENT_ID=
   GOOGLE_OAUTH_CLIENT_SECRET=

   MICROSOFT_GRAPH_OAUTH_CLIENT_ID=
   MICROSOFT_GRAPH_OAUTH_CLIENT_SECRET=

   AWS_ACCESS_KEY_ID=
   AWS_SECRET_ACCESS_KEY=
   ```

   <PartialOAuthCredentials />

3. Optional: Set the `WEBHOOK_BASE_URL` to the base address for your OAuth connector endpoints. If set, the OAuth connector webhook URLs are constructed as `WEBHOOK_BASE_URL/connectors/${provider}/webhook`. This option is required to enable automatic ingestion from cloud storage.

4. Save the `.env` file.

5. For each connector, you must register the OpenRAG redirect URIs in your OAuth apps:

   * Local deployments: `http://localhost:3000/auth/callback`
   * Production deployments: `https://your-domain.com/auth/callback`

   The redirect URIs are used for the cloud storage connector webhooks. For Google, the redirect URIs are also used to redirect users back to OpenRAG after they sign in.

6. Restart your OpenRAG containers:

   <PartialDockerComposeUp />

7. Access the OpenRAG frontend at `http://localhost:3000`.

   If you provided Google OAuth credentials, you must sign in with Google before you are redirected to your OpenRAG instance.

</TabItem>
</Tabs>

### Ingest files from cloud storage

To ingest knowledge with a cloud storage connector, do the following:

1. Click <Icon name="Library" aria-hidden="true"/> **Knowledge** to view your OpenSearch knowledge base.

2. Click **Add Knowledge**, and then select a storage provider.

3. On the **Add Cloud Knowledge** page, click **Add Files**, and then select the files and folders to ingest from the connected storage.

4. Click **Ingest Files**.

The selected files are processed in the background through the **OpenSearch Ingestion** flow.

<PartialIngestionFlow />

You can [monitor ingestion](#monitor-ingestion) to see the progress of the uploads and check for failed uploads.

## Ingest knowledge from URLs {#url-flow}

When using the OpenRAG chat, you can enter URLs into the chat to be ingested in real-time during your conversation.

:::info
The chat cannot ingest URLs that end in static document file extensions like `.pdf`.
To upload these types of files, see [Ingest local files and folders](#ingest-local-files-and-folders) and [Ingest files with cloud storage connectors](#oauth-ingestion).
:::

OpenRAG runs the **OpenSearch URL Ingestion** flow to ingest web content from URLs.
This flow isn't directly accessible from the OpenRAG user interface.
Instead, this flow is called by the [**OpenRAG OpenSearch Agent** flow](/chat#flow) as a Model Context Protocol (MCP) tool.
The agent can call this component to fetch web content from a given URL, and then ingest that content into your OpenSearch knowledge base.
Like all OpenRAG flows, you can [inspect the flow in Langflow](/agents#inspect-and-modify-flows), and you can customize it.
For more information about MCP in Langflow, see the Langflow documentation on [MCP clients](https://docs.langflow.org/mcp-client) and [MCP servers](https://docs.langflow.org/mcp-tutorial).

## Monitor ingestion {#monitor-ingestion}

Depending on the amount of data to ingest, document ingestion can take a few seconds, minutes, or longer.
For this reason, document ingestion tasks run in the background.

In the OpenRAG user interface, a badge is shown on <Icon name="Bell" aria-hidden="true"/> **Tasks** when OpenRAG tasks are active.
Click <Icon name="Bell" aria-hidden="true"/> **Tasks** to inspect and cancel tasks.
Tasks are separated into multiple sections:

* The **Active Tasks** section includes all tasks that are **Pending**, **Running**, or **Processing**:

   * **Pending**: The task is queued and waiting to start.
   * **Running**: The task is actively processing files.
   * **Processing**: The task is performing ingestion operations.

   To stop an active task, click <Icon name="X" aria-hidden="true"/> **Cancel**. Canceling a task stops processing immediately and marks the ingestion as failed.

* The **Recent Tasks** section lists recently finished tasks.

   :::warning
   **Completed** doesn't mean success.

   A completed task can report successful ingestions, failed ingestions, or both, depending on the number of files processed.
   :::

   Check the **Success** and **Failed** counts for each completed task to determine the overall success rate.

   **Failed** means [something went wrong during ingestion](/support/troubleshoot#document-ingestion-or-similarity-search-issues), or the task was manually canceled.

For each task, depending on its state, you can find the task ID, start time, duration, number of files processed successfully, number of files that failed, and the number of files enqueued for processing.

### Ingestion performance expectations

The following performance test was conducted with Docling Serve.

On a local VM with 7 vCPUs and 8 GiB RAM, OpenRAG ingested approximately 5.03 GB across 1,083 files in about 42 minutes.
This equates to approximately 2.4 documents per second.

You can generally expect equal or better performance on developer laptops, and significantly faster performance on servers.
Throughput scales with CPU cores, memory, storage speed, and configuration choices, such as the embedding model, chunk size, overlap, and concurrency.

This test returned 12 error, approximately 1.1 percent of the total files ingested.
All errors were file-specific, and they didn't stop the pipeline.

<details>
<summary>Ingestion performance test details</summary>

* Ingestion dataset:

   * Total files: 1,083 items mounted
   * Total size on disk: 5,026,474,862 bytes (approximately 5.03 GB)

* Hardware specifications:

   * Machine: Apple M4 Pro
   * Podman VM:

     * Name: podman-machine-default
     * Type: applehv
     * vCPUs: 7
     * Memory: 8 GiB
     * Disk size: 100 GiB

* Test results:

   ```text
   2025-09-24T22:40:45.542190Z /app/src/main.py:231 Ingesting default documents when ready disable_langflow_ingest=False
   2025-09-24T22:40:45.546385Z /app/src/main.py:270 Using Langflow ingestion pipeline for default documents file_count=1082
   ...
   2025-09-24T23:19:44.866365Z /app/src/main.py:351 Langflow ingestion completed success_count=1070 error_count=12 total_files=1082
   ```

* Elapsed time: Approximately 42 minutes 15 seconds (2,535 seconds)

* Throughput: Approximately 2.4 documents per second

</details>

## See also

* [Configure knowledge](/knowledge)
* [Filter knowledge](/knowledge-filters)
* [Chat with knowledge](/chat)
* [Inspect and modify flows](/agents#inspect-and-modify-flows)
* [Troubleshoot document ingestion or similarity search issues](/support/troubleshoot#document-ingestion-or-similarity-search-issues)